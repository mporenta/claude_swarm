# Airflow Agent Configuration - Environment Variables
#
# Copy this file to .env.airflow and update paths for your local setup
#
# USAGE:
#   1. Copy: cp .env.airflow.example .env.airflow
#   2. Edit .env.airflow with your actual paths
#   3. Source: set -a; source .env.airflow; set +a
#   4. Run: python main.py --config yaml_files/airflow_agent_options.local.yaml
#
# NOTE: These paths will differ on:
#   - Your local machine
#   - Teammate machines
#   - AWS Bedrock (uses temp directories)
#   - CI/CD environments

# =============================================================================
# AIRFLOW 2.0 PROJECT PATHS
# =============================================================================

# Root directory of the Airflow 2.0 project
# This is where the main data-airflow repository is located
#
# Examples:
#   Local Dev:    /home/dev/projects/data-airflow
#   AWS Bedrock:  /tmp/bedrock-workspace/data-airflow
#   Mac:          /Users/yourname/workspace/data-airflow
AIRFLOW_2_ROOT=/home/dev/app/trading-app/airflow/data-airflow

# Airflow 2.0 DAGs directory (usually {AIRFLOW_2_ROOT}/dags)
AIRFLOW_2_DAGS_DIR=${AIRFLOW_2_ROOT}/dags

# =============================================================================
# AIRFLOW LEGACY (1.0) PROJECT PATHS
# =============================================================================

# Root directory of the Airflow Legacy project
# This is the old Airflow 1.0 codebase you're migrating FROM
#
# Examples:
#   Local Dev:    /home/dev/projects/data-airflow-legacy
#   AWS Bedrock:  /tmp/bedrock-workspace/data-airflow-legacy
#   Mac:          /Users/yourname/workspace/data-airflow-legacy
AIRFLOW_LEGACY_ROOT=/home/dev/app/trading-app/airflow/data-airflow-legacy

# Airflow Legacy DAGs directory (usually {AIRFLOW_LEGACY_ROOT}/dags)
AIRFLOW_LEGACY_DAGS_DIR=${AIRFLOW_LEGACY_ROOT}/dags

# =============================================================================
# AIRFLOW CONFIGURATION
# =============================================================================

# Airflow home directory (usually same as AIRFLOW_2_ROOT)
AIRFLOW_HOME=${AIRFLOW_2_ROOT}

# Python path additions (colon-separated list)
# Add any additional directories needed for imports
PYTHONPATH=/opt/airflow/dags:${AIRFLOW_2_ROOT}:${AIRFLOW_2_ROOT}/dags/common

# =============================================================================
# CLAUDE MODEL CONFIGURATION
# =============================================================================

# Model to use for orchestration
# Options: claude-sonnet-4-5-20250929, claude-opus-4-20250514, claude-haiku-4-5-20251001
CLAUDE_MODEL=claude-sonnet-4-5-20250929

# =============================================================================
# ENVIRONMENT-SPECIFIC EXAMPLES
# =============================================================================

# --- LOCAL DEVELOPMENT (Linux) ---
# AIRFLOW_2_ROOT=/home/dev/projects/data-airflow
# AIRFLOW_LEGACY_ROOT=/home/dev/projects/data-airflow-legacy

# --- LOCAL DEVELOPMENT (Mac) ---
# AIRFLOW_2_ROOT=/Users/yourname/workspace/data-airflow
# AIRFLOW_LEGACY_ROOT=/Users/yourname/workspace/data-airflow-legacy

# --- AWS BEDROCK ---
# AIRFLOW_2_ROOT=/tmp/bedrock-workspace-abc123/data-airflow
# AIRFLOW_LEGACY_ROOT=/tmp/bedrock-workspace-abc123/data-airflow-legacy

# --- CI/CD (GitHub Actions) ---
# AIRFLOW_2_ROOT=/home/runner/work/data-airflow/data-airflow
# AIRFLOW_LEGACY_ROOT=/home/runner/work/data-airflow-legacy/data-airflow-legacy

# =============================================================================
# QUICK START COMMANDS
# =============================================================================
#
# After editing this file:
#
# 1. Source environment variables:
#    set -a && source .env.airflow && set +a
#
# 2. Verify paths are set:
#    echo "Airflow 2: $AIRFLOW_2_ROOT"
#    echo "Legacy: $AIRFLOW_LEGACY_ROOT"
#
# 3. Run orchestration:
#    python main.py --config yaml_files/airflow_agent_options.local.yaml
#
# 4. Or use the helper script (if available):
#    ./run_airflow_migration.sh
#
# =============================================================================
